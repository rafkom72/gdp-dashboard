{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fdec0cfa",
      "metadata": {
        "id": "fdec0cfa"
      },
      "source": [
        "\n",
        "# Week 1 ‚Äî Introduction to AI Engineering\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/tulane-intro-ai-engineering/main/blob/main/lectures/intro_lecture.ipynb\" target=\"_blank\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\"/>\n",
        "</a>\n",
        "\n",
        "üìò **Theme:** From Algorithms ‚Üí Systems ‚Üí Reliability  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "### **Learning Objectives**\n",
        "By the end of this week, you will be able to:\n",
        "1. Explain what *AI Engineering* means and how it differs from algorithmic AI.\n",
        "2. Describe real-world successes and limitations of large language models (LLMs).\n",
        "3. Interpret key failure types: hallucinations, bias, brittleness.\n",
        "4. Build a simple mental model of how LLMs generate text.\n",
        "5. Understand the *Unifying System Diagram* of LLM systems.\n",
        "6. Run your first API call and reason about it scientifically.\n",
        "7. Reflect on reliability, trust, and the iterative design mindset.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "891c5a58",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "891c5a58",
        "outputId": "30f7e24b-72d8-4f15-b049-1cb277cf3980"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîß Setting up your environment...\n",
            "  ‚Üí Installing core packages...\n",
            "installing mermaid-python\n",
            "  ‚Üí Setting random seed for reproducible results...\n",
            "  ‚Üí Checking API key...\n",
            "üîë Enter your OpenAI API key.\n",
            "   (It will only be stored in this Colab runtime - it's safe!)\n",
            "   Get your key from: https://platform.openai.com/api-keys\n",
            "OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "‚úÖ API key set.\n",
            "  ‚Üí Adding course files to path...\n",
            "‚úÖ Setup complete!\n",
            "‚úÖ lab1_setup: environment ready.\n"
          ]
        }
      ],
      "source": [
        "# @title Setup (Run this first)\n",
        "!git clone --depth 1 -q https://github.com/tulane-intro-ai-engineering/main.git\n",
        "import sys; sys.path.append(\"/content/main\")\n",
        "from course_utils import lab1_setup, show_mermaid\n",
        "\n",
        "lab1_setup()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48865198",
      "metadata": {
        "id": "48865198"
      },
      "source": [
        "\n",
        "## üß© **Day 1 ‚Äî What Does It Mean to Engineer AI?**\n",
        "---\n",
        "**Guiding question:**  \n",
        "> How is AI Engineering different from building models, and why does that matter?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "52da2b1b",
      "metadata": {
        "id": "52da2b1b"
      },
      "source": [
        "\n",
        "### Welcome & Motivation\n",
        "\n",
        "\n",
        "> ‚ÄúWho here has used ChatGPT or another AI tool this week?‚Äù\n",
        "\n",
        "<br><br><br><br><br><br>\n",
        "\n",
        "> ‚ÄúWhen it worked well, why? When did it fail?‚Äù\n",
        "\n",
        "<br><br><br><br><br><br>\n",
        "\n",
        "> ‚ÄúThat gap ‚Äî between impressive and unreliable ‚Äî is what AI engineers work to close.‚Äù\n",
        "\n",
        "**AI Engineering = Designing systems that are repeatable, safe, and measurable.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4514fb4",
      "metadata": {
        "id": "b4514fb4"
      },
      "source": [
        "\n",
        "### What Is AI Engineering (and How Is It Different)?\n",
        "\n",
        "| Course | Focus | Core Question |\n",
        "|:--------|:--------|:-------------|\n",
        "| *Intro to AI* | Symbolic reasoning, search | ‚ÄúHow do we find the best move?‚Äù |\n",
        "| *Intro to Deep Learning* | Model architectures | ‚ÄúHow does a CNN learn features?‚Äù |\n",
        "| *NLP* | Linguistic representation | ‚ÄúHow can we classify text?‚Äù |\n",
        "| **AI Engineering** | System reliability, safety | ‚ÄúHow can we make AI systems reliable and auditable?‚Äù |\n",
        "\n",
        "> AI Engineering bridges models, systems, and people. Engineers design pipelines, test behaviors, and trade off between accuracy, latency, and safety.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1585866a",
      "metadata": {
        "id": "1585866a"
      },
      "source": [
        "\n",
        "### LLM Successes and Failures\n",
        "\n",
        "We'll contrast **impressive** and **unreliable** examples to motivate why *engineering* matters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c4cab1b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "c4cab1b0",
        "outputId": "ecaba39d-f67e-4a4a-bf4b-eaa3708f8c75"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RateLimitError",
          "evalue": "Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3975241205.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m response = client.responses.create(\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4o-mini\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Explain how a neural network recognizes handwriting, in one paragraph.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/responses/responses.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, background, conversation, include, input, instructions, max_output_tokens, max_tool_calls, metadata, model, parallel_tool_calls, previous_response_id, prompt, prompt_cache_key, prompt_cache_retention, reasoning, safety_identifier, service_tier, store, stream, stream_options, temperature, text, tool_choice, tools, top_logprobs, top_p, truncation, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    864\u001b[0m         \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeout\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mNotGiven\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnot_given\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     ) -> Response | Stream[ResponseStreamEvent]:\n\u001b[0;32m--> 866\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    867\u001b[0m             \u001b[0;34m\"/responses\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         )\n\u001b[0;32m-> 1259\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1261\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1045\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, read the docs: https://platform.openai.com/docs/guides/error-codes/api-errors.', 'type': 'insufficient_quota', 'param': None, 'code': 'insufficient_quota'}}"
          ]
        }
      ],
      "source": [
        "# @title Example 1 ‚Äî Helpful Assistant\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=\"Explain how a neural network recognizes handwriting, in one paragraph.\"\n",
        ")\n",
        "display(response.output_text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3b8f228",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "c3b8f228",
        "outputId": "188c6cca-2491-448f-ae3b-67e5a159cdc9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'The Great Wall of China is made of materials like stone and brick that contain minerals which interfere with satellite signals. As these minerals reflect and refract the signals, it creates noise and distortion, making it difficult for satellites to accurately receive and transmit data across the wall.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'üí≠ Note: This is a hallucination ‚Äî the model confidently states something that is false.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "'   The Great Wall does NOT block satellite signals. This is why we need to test and verify AI outputs!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Example 2 ‚Äî Confidently Wrong Model (Hallucination)\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-3.5-turbo-0125\",\n",
        "    input=\"Explain in 50 words or less how the Great Wall of China blocks satellite signals\"\n",
        ")\n",
        "display(response.output_text)\n",
        "display(\"üí≠ Note: This is a hallucination ‚Äî the model confidently states something that is false.\")\n",
        "display(\"   The Great Wall does NOT block satellite signals. This is why we need to test and verify AI outputs!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e72a6bae",
      "metadata": {
        "id": "e72a6bae"
      },
      "source": [
        "\n",
        "### üî§ Building a Mental Model of LLMs\n",
        "\n",
        "Think of an LLM as an *autocomplete engine on steroids* ‚Äî predicting what comes next, token by token.\n",
        "\n",
        "**Key insight:** The model doesn't \"know\" facts ‚Äî it predicts what text is likely to come next based on patterns it learned from training data. This is why it can be both impressive and unreliable.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91af20dd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "91af20dd",
        "outputId": "e713ddb5-a972-40d4-ae36-caf7f137a4ac"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Artificial intelligence (AI) refers to the simulation of human intelligence in machines that are programmed to think and learn. AI systems can perform tasks that typically require human-like understanding, such as problem-solving, learning from experience, adapting to new information, and responding to complex requests.\n\nAI encompasses various subfields, including:\n\n1. **Machine Learning**: A method where algorithms learn from data to make decisions or predictions without being explicitly programmed.\n  \n2. **Natural Language Processing (NLP)**: The ability of machines to understand, interpret, and respond to human language.\n  \n3. **Computer Vision**: Enabling machines to interpret and make decisions based on visual input from the world (like images or videos).\n  \n4. **Robotics**: Combining AI with physical machines that can perform tasks autonomously or semi-autonomously.\n\nAI has numerous applications, including virtual assistants, recommendation systems, autonomous vehicles, healthcare diagnostics, and more. It continues to evolve rapidly, influencing many aspects of everyday life and various industries."
          },
          "metadata": {}
        }
      ],
      "source": [
        "from IPython.display import Markdown\n",
        "prompt = \"Artificial intelligence is...\"\n",
        "response = client.responses.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    input=prompt\n",
        ")\n",
        "display(Markdown(response.output_text))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5201e304",
      "metadata": {
        "id": "5201e304"
      },
      "source": [
        "\n",
        "### üß† The Unifying System Diagram\n",
        "\n",
        "This 5-part diagram will guide us through the course:\n",
        "\n",
        "**User Interaction ‚Üí Prompt & Control ‚Üí Tools & Augmentation ‚Üí Core LLM ‚Üí Output & Monitoring**\n",
        "\n",
        "\n",
        "\n",
        "<!-- ![LLM System Diagram](https://github.com/tulane-intro-ai-engineering/main/blob/main/lectures/llm_workflow.png?raw=true) -->\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "veNKZJ-Ow6O6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "veNKZJ-Ow6O6",
        "outputId": "dc78f384-36f0-4e75-d55a-8e8796661b9c",
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<mermaid.mermaid.Mermaid at 0x7e51839a9fa0>"
            ],
            "text/html": [
              "\n",
              "        <div class=\"mermaid-3d3b1b8e-a22d-4ddd-8a29-4896af03a5a8\"></div>\n",
              "        <script type=\"module\">\n",
              "            import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.1.0/+esm'\n",
              "            const graphDefinition = 'graph TD\\n    subgraph User Interaction\\n    U[\"üë§ Users<br/>Queries / Inputs\"]:::user --> IH[\"Input Handling<br/>‚Ä¢ Formatting<br/>‚Ä¢ Validation<br/>‚Ä¢ Safety Filters\"]:::process\\n    end\\n\\n    subgraph Prompt & Control\\n    IH --> PC(\"Prompt / Control<br/>‚Ä¢ Instructions<br/>‚Ä¢ Examples<br/>‚Ä¢ Constraints<br/>‚Ä¢ Parameters\"):::control\\n    end\\n\\n    subgraph Tools & Augmentation\\n    PC --> TF{\"Tools / Functions<br/>‚Ä¢ External APIs\"}:::tool\\n    PC --> RAG{\"Retrieval (RAG)<br/>‚Ä¢ Embeddings<br/>‚Ä¢ Vector Store<br/>‚Ä¢ Top-k Search\"}:::tool\\n    end\\n\\n    subgraph Core LLM\\n    TF --> LLM[\"Core LLM<br/>‚Ä¢ Next-token generation<br/>‚Ä¢ Sampling<br/>‚Ä¢ Fine-tuned model\"]:::model\\n    RAG --> LLM\\n    PC --> LLM\\n    end\\n\\n    subgraph Output & Monitoring\\n    LLM --> OP[\"Output Processing<br/>‚Ä¢ Formatting<br/>‚Ä¢ Citations<br/>‚Ä¢ Refusals<br/>‚Ä¢ Trust Signals\"]:::output --> O(\"Final Output\"):::output\\n    O --> LM[\"Logging & Monitoring<br/>‚Ä¢ Prompts & Responses<br/>‚Ä¢ Metrics<br/>‚Ä¢ Drift Detection\"]:::monitor\\n    end\\n\\n    classDef user fill:#d1e7dd,stroke:#333,stroke-width:1px;\\n    classDef process fill:#e2e3e5,stroke:#333,stroke-width:1px;\\n    classDef control fill:#cfe2ff,stroke:#333,stroke-width:1px;\\n    classDef tool fill:#fff3cd,stroke:#333,stroke-width:1px;\\n    classDef model fill:#f8d7da,stroke:#333,stroke-width:1px;\\n    classDef output fill:#e9ecef,stroke:#333,stroke-width:1px;\\n    classDef monitor fill:#fefefe,stroke:#333,stroke-width:1px;\\n';\n",
              "            const element = document.querySelector('.mermaid-3d3b1b8e-a22d-4ddd-8a29-4896af03a5a8');\n",
              "            const { svg } = await mermaid.render('graphDiv-3d3b1b8e-a22d-4ddd-8a29-4896af03a5a8', graphDefinition);\n",
              "            element.innerHTML = svg;\n",
              "        </script>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @title Detailed System Diagram\n",
        "\n",
        "show_mermaid(\"\"\"\n",
        "graph TD\n",
        "    subgraph User Interaction\n",
        "    U[\"üë§ Users<br/>Queries / Inputs\"]:::user --> IH[\"Input Handling<br/>‚Ä¢ Formatting<br/>‚Ä¢ Validation<br/>‚Ä¢ Safety Filters\"]:::process\n",
        "    end\n",
        "\n",
        "    subgraph Prompt & Control\n",
        "    IH --> PC(\"Prompt / Control<br/>‚Ä¢ Instructions<br/>‚Ä¢ Examples<br/>‚Ä¢ Constraints<br/>‚Ä¢ Parameters\"):::control\n",
        "    end\n",
        "\n",
        "    subgraph Tools & Augmentation\n",
        "    PC --> TF{\"Tools / Functions<br/>‚Ä¢ External APIs\"}:::tool\n",
        "    PC --> RAG{\"Retrieval (RAG)<br/>‚Ä¢ Embeddings<br/>‚Ä¢ Vector Store<br/>‚Ä¢ Top-k Search\"}:::tool\n",
        "    end\n",
        "\n",
        "    subgraph Core LLM\n",
        "    TF --> LLM[\"Core LLM<br/>‚Ä¢ Next-token generation<br/>‚Ä¢ Sampling<br/>‚Ä¢ Fine-tuned model\"]:::model\n",
        "    RAG --> LLM\n",
        "    PC --> LLM\n",
        "    end\n",
        "\n",
        "    subgraph Output & Monitoring\n",
        "    LLM --> OP[\"Output Processing<br/>‚Ä¢ Formatting<br/>‚Ä¢ Citations<br/>‚Ä¢ Refusals<br/>‚Ä¢ Trust Signals\"]:::output --> O(\"Final Output\"):::output\n",
        "    O --> LM[\"Logging & Monitoring<br/>‚Ä¢ Prompts & Responses<br/>‚Ä¢ Metrics<br/>‚Ä¢ Drift Detection\"]:::monitor\n",
        "    end\n",
        "\n",
        "    classDef user fill:#d1e7dd,stroke:#333,stroke-width:1px;\n",
        "    classDef process fill:#e2e3e5,stroke:#333,stroke-width:1px;\n",
        "    classDef control fill:#cfe2ff,stroke:#333,stroke-width:1px;\n",
        "    classDef tool fill:#fff3cd,stroke:#333,stroke-width:1px;\n",
        "    classDef model fill:#f8d7da,stroke:#333,stroke-width:1px;\n",
        "    classDef output fill:#e9ecef,stroke:#333,stroke-width:1px;\n",
        "    classDef monitor fill:#fefefe,stroke:#333,stroke-width:1px;\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Where do you think reliability issues arise most often?**\n",
        "\n",
        "<br><br><br>\n"
      ],
      "metadata": {
        "id": "mqVXHNp_RKK4"
      },
      "id": "mqVXHNp_RKK4"
    },
    {
      "cell_type": "markdown",
      "id": "bddd733e",
      "metadata": {
        "id": "bddd733e"
      },
      "source": [
        "\n",
        "### ü§ù Trust Activity\n",
        "\n",
        "Scenario brainstorming (small groups):  \n",
        "- Would you trust AI for medical advice? grading essays? writing policy?  \n",
        "Mark which *stages* of the pipeline you‚Äôd trust vs. audit.\n",
        "\n",
        "**Discussion:** What common patterns emerge?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "427591b9",
      "metadata": {
        "id": "427591b9"
      },
      "source": [
        "\n",
        "### Course Overview & Lab 1 Preview\n",
        "\n",
        "- Weekly rhythm: Tues = concept, Thurs = lab.  \n",
        "- Labs = *mini scientific investigations.*  \n",
        "- **Lab 1:** make your first API call, measure model behavior.\n",
        "\n",
        "> ‚ÄúNext time, we‚Äôll talk directly to this system ‚Äî through an API.‚Äù\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zCTeh8IpRWXR"
      },
      "id": "zCTeh8IpRWXR",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "739772cb",
      "metadata": {
        "id": "739772cb"
      },
      "source": [
        "\n",
        "## üíª **Day 2 ‚Äî From Concept to Code: APIs and the Scientific Method**\n",
        "\n",
        "**Guiding question:**  \n",
        "> How do we interact with an AI system ‚Äî and test it like scientists?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7722b7ee",
      "metadata": {
        "id": "7722b7ee"
      },
      "source": [
        "\n",
        "### üåê What Is an API?\n",
        "\n",
        "> An **API** (Application Programming Interface) is a set of rules and tools that lets one piece of software talk to another.\n",
        "\n",
        "Analogy: ordering from a restaurant menu ‚Äî you don‚Äôt enter the kitchen, you make a request.\n",
        "\n",
        "Diagram:\n",
        "```\n",
        "User ‚Üí Request (JSON) ‚Üí Server ‚Üí Model ‚Üí Response (JSON)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ee20d56a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ee20d56a",
        "outputId": "cc4c541d-9939-4efc-f3f9-491e03a083e1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'gpt-4o-mini',\n",
              " 'input': 'What is the capital of Japan?',\n",
              " 'instructions': 'You are a helpful assistant.'}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# Example API request\n",
        "example_request = {\n",
        "    \"model\": \"gpt-4o-mini\",\n",
        "    \"input\": \"What is the capital of Japan?\",\n",
        "    # \"system\" prompt, which is pre-pended to the input.\n",
        "    \"instructions\": \"You are a helpful assistant.\"\n",
        "}\n",
        "example_request"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "81ed1bdf",
      "metadata": {
        "id": "81ed1bdf"
      },
      "source": [
        "\n",
        "### ‚ö° Live Demo: Hello API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5455add6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5455add6",
        "outputId": "b90509c0-074e-4cdd-c09a-ea66e3f654e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Japan is Tokyo.\n",
            "Tokens used: 32\n"
          ]
        }
      ],
      "source": [
        "response = client.responses.create(**example_request)\n",
        "print(response.output_text)\n",
        "print(\"Tokens used:\", response.usage.total_tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Z8IgnUOP2eG1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8IgnUOP2eG1",
        "outputId": "b8ad9376-0854-43dc-e9ae-ab791d1e4d21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"id\": \"resp_0e9892f328886b8e00696525a7144c8195be83be98c54c03fc\",\n",
            "  \"created_at\": 1768236455.0,\n",
            "  \"error\": null,\n",
            "  \"incomplete_details\": null,\n",
            "  \"instructions\": \"You are a helpful assistant.\",\n",
            "  \"metadata\": {},\n",
            "  \"model\": \"gpt-4o-mini-2024-07-18\",\n",
            "  \"object\": \"response\",\n",
            "  \"output\": [\n",
            "    {\n",
            "      \"id\": \"msg_0e9892f328886b8e00696525a8336c81958612b2188facdf01\",\n",
            "      \"content\": [\n",
            "        {\n",
            "          \"annotations\": [],\n",
            "          \"text\": \"The capital of Japan is Tokyo.\",\n",
            "          \"type\": \"output_text\",\n",
            "          \"logprobs\": []\n",
            "        }\n",
            "      ],\n",
            "      \"role\": \"assistant\",\n",
            "      \"status\": \"completed\",\n",
            "      \"type\": \"message\"\n",
            "    }\n",
            "  ],\n",
            "  \"parallel_tool_calls\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"tool_choice\": \"auto\",\n",
            "  \"tools\": [],\n",
            "  \"top_p\": 1.0,\n",
            "  \"background\": false,\n",
            "  \"conversation\": null,\n",
            "  \"max_output_tokens\": null,\n",
            "  \"max_tool_calls\": null,\n",
            "  \"previous_response_id\": null,\n",
            "  \"prompt\": null,\n",
            "  \"prompt_cache_key\": null,\n",
            "  \"prompt_cache_retention\": null,\n",
            "  \"reasoning\": {\n",
            "    \"effort\": null,\n",
            "    \"generate_summary\": null,\n",
            "    \"summary\": null\n",
            "  },\n",
            "  \"safety_identifier\": null,\n",
            "  \"service_tier\": \"default\",\n",
            "  \"status\": \"completed\",\n",
            "  \"text\": {\n",
            "    \"format\": {\n",
            "      \"type\": \"text\"\n",
            "    },\n",
            "    \"verbosity\": \"medium\"\n",
            "  },\n",
            "  \"top_logprobs\": 0,\n",
            "  \"truncation\": \"disabled\",\n",
            "  \"usage\": {\n",
            "    \"input_tokens\": 24,\n",
            "    \"input_tokens_details\": {\n",
            "      \"cached_tokens\": 0\n",
            "    },\n",
            "    \"output_tokens\": 8,\n",
            "    \"output_tokens_details\": {\n",
            "      \"reasoning_tokens\": 0\n",
            "    },\n",
            "    \"total_tokens\": 32\n",
            "  },\n",
            "  \"user\": null,\n",
            "  \"billing\": {\n",
            "    \"payer\": \"developer\"\n",
            "  },\n",
            "  \"completed_at\": 1768236456,\n",
            "  \"frequency_penalty\": 0.0,\n",
            "  \"presence_penalty\": 0.0,\n",
            "  \"store\": true\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "print(response.model_dump_json(indent=2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`client.responses.create(...)` is an wrapper for one **HTTP POST** call:\n",
        "\n",
        "* It a request to **`POST https://api.openai.com/v1/responses`**\n",
        "* The arguments (`model`, `input`, optional `instructions`, etc.) become a **JSON request body**\n",
        "* The Open AI API key is sent in the **Authorization** header (Bearer token)\n",
        "* OpenAI returns an **HTTP response** (e.g., `200 OK`) containing a structured JSON ‚Äúresponse‚Äù object; the result exposes the generated text as `response.output_text`\n"
      ],
      "metadata": {
        "id": "FJcGdANnC1h-"
      },
      "id": "FJcGdANnC1h-"
    },
    {
      "cell_type": "markdown",
      "id": "cb7ace55",
      "metadata": {
        "id": "cb7ace55"
      },
      "source": [
        "\n",
        "### üß™ Mini Experiment: Prompt Wording and Response Length\n",
        "\n",
        "We'll test whether prompt phrasing changes the output length.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9182ecd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "9182ecd0",
        "outputId": "0a242819-f9d0-4e88-87b9-2fec3f8d6b48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: Explain AI engineering in one sentence.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "AI engineering is the discipline of designing, developing, and deploying artificial intelligence solutions by integrating principles from computer science, data science, and software engineering to solve real-world problems."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length: 224 characters\n",
            "\n",
            "Prompt: Explain AI engineering in one sentence using technical language.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "AI engineering is the discipline that encompasses the systematic design, development, and deployment of artificial intelligence systems, integrating algorithms, data architecture, and software engineering principles to create robust and scalable solutions."
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length: 256 characters\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prompts = [\n",
        "    \"Explain AI engineering in one sentence.\",\n",
        "    \"Explain AI engineering in one sentence using technical language.\"\n",
        "]\n",
        "\n",
        "for p in prompts:\n",
        "    resp = client.responses.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        input=p)\n",
        "    text = resp.output_text\n",
        "    print(f\"Prompt: {p}\")\n",
        "    display(Markdown(text))\n",
        "    print(f\"Length: {len(text)} characters\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cab9bf46",
      "metadata": {
        "id": "cab9bf46"
      },
      "source": [
        "\n",
        "### üß≠ Responsible Iteration & Measurement\n",
        "\n",
        "**AI engineers think in loops:**\n",
        "1. Observe model behavior.\n",
        "2. Adjust prompt or parameters.\n",
        "3. Measure results.\n",
        "4. Reflect and repeat.\n",
        "\n",
        "This is not ‚Äúprompt hacking‚Äù ‚Äî it‚Äôs controlled experimentation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b422b161",
      "metadata": {
        "id": "b422b161"
      },
      "source": [
        "\n",
        "### üß´ Introducing Lab 1\n",
        "\n",
        "**What you'll do in Lab 1:**\n",
        "- Make your first API call to an LLM\n",
        "- **Experiment** with different system prompts (using the scientific method!)\n",
        "- Build a simple web app with Gradio\n",
        "- Observe how system prompts affect model behavior\n",
        "\n",
        "**Lab structure:**\n",
        "- **Setup** (clone repo + bootstrap)\n",
        "- **Pre-Lab** (conceptual warmup)\n",
        "- **Scientific Process** (Question ‚Üí Hypothesis ‚Üí Experiment ‚Üí Measurement)\n",
        "- **Experiment** (test different system prompts)\n",
        "- **Results & Reflection** (connect to reliability)\n",
        "\n",
        "**Connection to today's lecture:** In the lab, you'll apply the scientific method we just discussed to test how system prompts change model outputs.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "485fcf0a",
      "metadata": {
        "id": "485fcf0a"
      },
      "source": [
        "\n",
        "### üë©‚Äçüíª In-Class Lab Work\n",
        "\n",
        "Students launch Lab 1 in Colab, test API, record first measurements.\n",
        "\n",
        "**Exit Ticket:**  \n",
        "> ‚ÄúWhat surprised you about the model‚Äôs response today?‚Äù\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d88ddb00",
      "metadata": {
        "id": "d88ddb00"
      },
      "source": [
        "\n",
        "<details>\n",
        "<summary>üßë‚Äçüè´ Instructor Notes</summary>\n",
        "\n",
        "**Pacing:**  \n",
        "- Demos should be quick; skip reruns if latency >15s.  \n",
        "- Prioritize discussion over full code explanations.  \n",
        "- If students struggle with setup, pause and debug as a group.\n",
        "\n",
        "**Engagement Tips:**  \n",
        "- Use polls for trust activities.  \n",
        "- Encourage sharing examples of ‚Äúgood/bad‚Äù AI behavior.\n",
        "\n",
        "**Extensions:**  \n",
        "- Optional demo: temperature or top_p for creativity.  \n",
        "- Ask students to predict which prompt will be longer *before* running it.\n",
        "</details>\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}